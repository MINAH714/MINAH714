👩‍💻 AI Application Developer | Backend & Cloud

AI 모델을 서비스로 연결하고,
클라우드 환경에서 안정적으로 운영하는 것에 관심이 많은 개발자입니다.
단순히 모델을 사용하는 것을 넘어, 비용·성능·UX를 고려한 AI 애플리케이션 구현을 지향합니다.

🧠 Tech Stack
🔤 Language

Python

⚙️ Backend

FastAPI

☁️ Cloud & DevOps

AWS

Docker

🤖 AI / ML

OpenAI API

Google Vertex AI

Ollama (Local LLM)

LM Studio

YOLO (Object Detection)

🧩 What I’ve Worked With

LLM 기반 AI API 서버 구축

OpenAI / Vertex AI 등 상용 LLM API 연동

Ollama, LM Studio를 활용한 로컬 LLM 실행 및 테스트

YOLO 기반 객체 탐지 모델 활용

FastAPI + Docker 기반 AI 서비스 컨테이너화

AWS 환경에서 서버 배포 및 운영 경험

🎯 Interests & Focus

AI 모델을 실제 서비스에 적용하는 방법

상황에 따라 상용 LLM과 로컬 LLM을 선택·전환하는 구조

AI 서비스의 비용 최적화와 응답 속도 개선

백엔드 관점에서의 AI 시스템 설계

🚀 Goal

“AI를 잘 쓰는 것에서 끝나지 않고,
운영 가능한 서비스로 완성하는 개발자”

기술을 나열하기보다,
문제를 정의하고 → 적절한 AI를 선택 → 서비스로 구현하는 경험을 쌓고 있습니다.

📌 Keywords

Python FastAPI Docker AWS
LLM OpenAI Vertex AI Ollama YOLO
AI Application Backend Developer

⭐️ 꾸준히 기록하고, 실험하고, 개선합니다.
